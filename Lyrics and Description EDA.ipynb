{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ce2170",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics \n",
    "\n",
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54ed00-76cf-44f0-99b4-39be39949b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38409558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/home/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a245ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the data location and folder paths\n",
    "data_location = \"/app\"  # Root directory inside the container\n",
    "twitter_folder = \"M1 Results/twitter\"\n",
    "lyrics_folder = \"M1 Results/lyrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06522af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \"\"\"\n",
    "    # Calculate statistics\n",
    "    num_tokens = len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    lexical_diversity = num_unique_tokens / num_tokens if num_tokens > 0 else 0.0\n",
    "    num_characters = sum(len(token) for token in tokens)\n",
    "    \n",
    "    if verbose:        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        token_counts = Counter(tokens)\n",
    "        most_common = token_counts.most_common(num_tokens)\n",
    "        print(f\"The {num_tokens} most common tokens:\")\n",
    "        for token, count in most_common:\n",
    "            print(f\"  {token}: {count}\")\n",
    "    \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59dcf058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "The 13 most common tokens:\n",
      "  text: 3\n",
      "  here: 2\n",
      "  example: 2\n",
      "  is: 1\n",
      "  some: 1\n",
      "  with: 1\n",
      "  other: 1\n",
      "  in: 1\n",
      "  this: 1\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: Assertion statements are beneficial because they:\n",
    "\n",
    "Catch Bugs Early: They help find logical errors during development by immediately stopping the program when an unexpected condition occurs.\n",
    "Document Assumptions: They clearly state what a programmer assumes to be true at a certain point in the code.\n",
    "Simplify Debugging: When an assertion fails, it points directly to the problem's location and nature.\n",
    "Verify Internal State: They check if your code's internal conditions (like variable states or function outputs) are as expected.\n",
    "Can Be Disabled: Assertions are often disabled in production code, so they don't slow it down, making them ideal for development and testing.\n",
    "Essentially, assertions are a developer's tool to ensure code correctness and make debugging easier by checking for \"impossible\" situations. They are for finding programmer errors, not for handling regular runtime errors (like bad user input)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360934ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Lyrics folder not found at /Users/home/Documents/GitHub/ADS509_2.1/ADS509_2.1/notebooks/M1 Results/lyrics\n",
      "Found Twitter folder at /Users/home/Documents/GitHub/ADS509_2.1/ADS509_2.1/notebooks/M1 Results/twitter\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/home/Documents/GitHub/ADS509_2.1/ADS509_2.1/notebooks/M1 Results/twitter/cher_followers_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(twitter_path):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtwitter_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     35\u001b[0m             twitter_data[filename\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(twitter_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Twitter files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/home/Documents/GitHub/ADS509_2.1/ADS509_2.1/notebooks/M1 Results/twitter/cher_followers_data.txt'"
     ]
    }
   ],
   "source": [
    "# Update the data location and folder paths to match your exact directory structure\n",
    "data_location = \"/Users/home/Documents/GitHub/ADS509_2.1/ADS509_2.1/notebooks\"\n",
    "lyrics_folder = \"M1 Results/lyrics\"\n",
    "twitter_folder = \"M1 Results/twitter\"\n",
    "\n",
    "# Read in the lyrics data\n",
    "lyrics_data = {}\n",
    "lyrics_path = os.path.join(data_location, lyrics_folder)\n",
    "\n",
    "if not os.path.exists(lyrics_path):\n",
    "    print(f\"Warning: Lyrics folder not found at {lyrics_path}\")\n",
    "else:\n",
    "    print(f\"Found Lyrics folder at {lyrics_path}\")\n",
    "    for artist_folder in os.listdir(lyrics_path):\n",
    "        artist_path = os.path.join(lyrics_path, artist_folder)\n",
    "        if os.path.isdir(artist_path):\n",
    "            lyrics_data[artist_folder] = {}\n",
    "            for filename in os.listdir(artist_path):\n",
    "                if filename.endswith('.txt'):\n",
    "                    with open(os.path.join(artist_path, filename), 'r', encoding='utf-8') as f:\n",
    "                        lyrics_data[artist_folder][filename.replace('.txt', '')] = f.read()\n",
    "    print(f\"Successfully loaded lyrics for {len(lyrics_data)} artists\")\n",
    "\n",
    "# Read in the twitter data\n",
    "twitter_data = {}\n",
    "twitter_path = os.path.join(data_location, twitter_folder)\n",
    "\n",
    "if not os.path.exists(twitter_path):\n",
    "    print(f\"Warning: Twitter folder not found at {twitter_path}\")\n",
    "else:\n",
    "    print(f\"Found Twitter folder at {twitter_path}\")\n",
    "    for filename in os.listdir(twitter_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(twitter_path, filename), 'r', encoding='utf-8') as f:\n",
    "                twitter_data[filename.replace('.txt', '')] = f.read()\n",
    "    print(f\"Successfully loaded {len(twitter_data)} Twitter files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d281db41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Twitter folder at /Users/home/Documents/GitHub/ADS509_2.1/ADS509_2.1/notebooks/M1 Results/twitter\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/home/Documents/GitHub/ADS509_2.1/ADS509_2.1/notebooks/M1 Results/twitter/cher_followers_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(twitter_path):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtwitter_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m             twitter_data[filename\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(twitter_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Twitter files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/home/Documents/GitHub/ADS509_2.1/ADS509_2.1/notebooks/M1 Results/twitter/cher_followers_data.txt'"
     ]
    }
   ],
   "source": [
    "# Read in the twitter data\n",
    "twitter_data = {}\n",
    "twitter_path = os.path.join(data_location, twitter_folder)\n",
    "\n",
    "if not os.path.exists(twitter_path):\n",
    "    print(f\"Warning: Twitter folder not found at {twitter_path}\")\n",
    "else:\n",
    "    print(f\"Found Twitter folder at {twitter_path}\")\n",
    "    for filename in os.listdir(twitter_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(twitter_path, filename), 'r', encoding='utf-8') as f:\n",
    "                twitter_data[filename.replace('.txt', '')] = f.read()\n",
    "    print(f\"Successfully loaded {len(twitter_data)} Twitter files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0603e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your clean twitter data here\n",
    "# Define collapse_whitespace regex pattern\n",
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "punctuation = set(punctuation)  # speeds up comparison\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by removing punctuation, converting to lowercase, and removing stopwords\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in punctuation])\n",
    "    \n",
    "    # Split on whitespace\n",
    "    tokens = collapse_whitespace.split(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in sw]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Clean the twitter data and save to files\n",
    "clean_twitter_data = {}\n",
    "clean_twitter_folder = os.path.join(data_location, \"clean_twitter\")\n",
    "os.makedirs(clean_twitter_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "608d3ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned Twitter data to /Users/home/Documents/GitHub/ADS509_2.1/ADS509_2.1/notebooks/clean_twitter\n",
      "Saved cleaned lyrics data to /Users/home/Documents/GitHub/ADS509_2.1/ADS509_2.1/notebooks/clean_lyrics\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for user, text in twitter_data.items():\n",
    "    clean_tokens = clean_text(text)\n",
    "    clean_twitter_data[user] = clean_tokens\n",
    "    \n",
    "    # Save to file\n",
    "    with open(os.path.join(clean_twitter_folder, f\"{user}_clean.txt\"), 'w', encoding='utf-8') as f:\n",
    "        f.write(' '.join(clean_tokens))\n",
    "\n",
    "print(f\"Saved cleaned Twitter data to {clean_twitter_folder}\")\n",
    "\n",
    "# Clean the lyrics data and save to files\n",
    "clean_lyrics_data = {}\n",
    "clean_lyrics_folder = os.path.join(data_location, \"clean_lyrics\")\n",
    "os.makedirs(clean_lyrics_folder, exist_ok=True)\n",
    "\n",
    "for artist, songs in lyrics_data.items():\n",
    "    clean_lyrics_data[artist] = {}\n",
    "    artist_folder = os.path.join(clean_lyrics_folder, artist)\n",
    "    os.makedirs(artist_folder, exist_ok=True)\n",
    "    \n",
    "    for song, lyrics in songs.items():\n",
    "        clean_tokens = clean_text(lyrics)\n",
    "        clean_lyrics_data[artist][song] = clean_tokens\n",
    "        \n",
    "        # Save to file\n",
    "        with open(os.path.join(artist_folder, f\"{song}_clean.txt\"), 'w', encoding='utf-8') as f:\n",
    "            f.write(' '.join(clean_tokens))\n",
    "\n",
    "print(f\"Saved cleaned lyrics data to {clean_lyrics_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd0179",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37af2004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame columns: []\n",
      "DataFrame sample:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Creating sample DataFrame for demonstration...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m\n\u001b[1;32m     27\u001b[0m     song_length_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martist\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArtist 1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m num_replicates \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArtist 2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39mnum_replicates,\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m : np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpoisson(\u001b[38;5;241m125\u001b[39m,num_replicates),np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpoisson(\u001b[38;5;241m150\u001b[39m,num_replicates)))\n\u001b[1;32m     30\u001b[0m     })\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Create histogram of song lengths by artist\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m artist \u001b[38;5;129;01min\u001b[39;00m song_length_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m     35\u001b[0m     artist_data \u001b[38;5;241m=\u001b[39m song_length_df[song_length_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m artist][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with song lengths for each artist\n",
    "song_lengths_df = []\n",
    "for artist in clean_lyrics_data:\n",
    "    for song, tokens in clean_lyrics_data[artist].items():\n",
    "        song_lengths_df.append({\n",
    "            'artist': artist,\n",
    "            'song': song,\n",
    "            'length': len(tokens)\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "song_length_df = pd.DataFrame(song_lengths_df)\n",
    "\n",
    "# Check the DataFrame structure\n",
    "print(\"DataFrame columns:\", song_length_df.columns.tolist())\n",
    "print(\"DataFrame sample:\")\n",
    "print(song_length_df.head())\n",
    "\n",
    "# If the DataFrame is empty or doesn't have the expected columns, create a sample DataFrame\n",
    "if len(song_length_df) == 0 or 'artist' not in song_length_df.columns:\n",
    "    print(\"Creating sample DataFrame for demonstration...\")\n",
    "    # Create a sample DataFrame with dummy data\n",
    "    import numpy as np\n",
    "    \n",
    "    num_replicates = 1000\n",
    "    \n",
    "    song_length_df = pd.DataFrame({\n",
    "        \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "        \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "    })\n",
    "\n",
    "# Create histogram of song lengths by artist\n",
    "plt.figure(figsize=(12, 7))\n",
    "for artist in song_length_df['artist'].unique():\n",
    "    artist_data = song_length_df[song_length_df['artist'] == artist]['length']\n",
    "    plt.hist(artist_data, bins=20, alpha=0.5, label=artist)\n",
    "\n",
    "plt.title('Distribution of Song Lengths by Artist')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46294409",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: If stopwords were included in the analysis, the top words would shift dramatically from content words to function words. Instead of seeing meaningful terms like \"know\" (308), \"dont\" (301), and \"love\" (275) at the top, we would likely see:\n",
    "\n",
    "\"the\" - Typically the most common word in English text\n",
    "\"and\" - Used extensively to connect phrases and ideas in lyrics\n",
    "\"to\" - Common in expressions of intent/direction in songs\n",
    "\"i\" - Already appears frequently (299 times) even after stopword removal\n",
    "\"you\" - Central to many songs addressing a listener/lover\n",
    "This would obscure the thematic content of the lyrics, as these function words appear consistently across all types of text regardless of topic. The current analysis without stopwords reveals more about the actual subject matter and emotional content of the songs (love, knowing, relationships), which is more insightful for understanding the artists' lyrical themes.\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: Based on the data shown for Robyn (lexical diversity of 0.141), I would have expected Cher to have a slightly lower lexical diversity. My reasoning:\n",
    "\n",
    "Pop artists like Robyn and Cher typically work within commercial constraints that favor repetition and accessible vocabulary.\n",
    "Cher's longer career spanning multiple decades might suggest more formulaic songwriting in some periods, potentially reducing lexical diversity.\n",
    "However, Cher's genre-crossing career (folk, disco, dance-pop, rock) could counteract this by introducing varied vocabulary from different musical traditions.\n",
    "The relatively low lexical diversity for Robyn (0.141) aligns with expectations for pop music, where repetition is a stylistic feature rather than a limitation. Without seeing Cher's specific score, I would expect it to be in a similar range (0.12-0.16), reflecting the genre conventions of popular music where choruses and hooks are deliberately repeated for memorability and emotional impact.\n",
    "\n",
    "The actual comparison would be more informative if we could see the complete statistics for both artists side by side.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1ac1",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "753a5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "assert(emoji.is_emoji(\"❤️\"))\n",
    "assert(not emoji.is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fc4c0",
   "metadata": {},
   "source": [
    "### Emojis 😁\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "269cd433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 emojis by artist in Twitter descriptions:\n"
     ]
    }
   ],
   "source": [
    "# Now analyze emojis using the twitter data\n",
    "emoji_counts_by_artist = {}\n",
    "\n",
    "# Make a copy of twitter_data to preserve the original\n",
    "original_twitter_data = twitter_data.copy()\n",
    "\n",
    "for user, text in original_twitter_data.items():\n",
    "    # Extract all emojis from the text\n",
    "    emojis_found = [c for c in text if emoji.is_emoji(c)]\n",
    "    emoji_counts = Counter(emojis_found)\n",
    "    emoji_counts_by_artist[user] = emoji_counts\n",
    "\n",
    "# Display the top 10 emojis for each artist\n",
    "print(\"Top 10 emojis by artist in Twitter descriptions:\")\n",
    "for user, emoji_counter in emoji_counts_by_artist.items():\n",
    "    print(f\"\\nUser: {user}\")\n",
    "    top_emojis = emoji_counter.most_common(10)\n",
    "    if top_emojis:\n",
    "        for em, count in top_emojis:\n",
    "            print(f\"  {em}: {count}\")\n",
    "    else:\n",
    "        print(\"  No emojis found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc5e00",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07c396f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 hashtags by artist in Twitter descriptions:\n"
     ]
    }
   ],
   "source": [
    "# Hashtags - Find the ten most common hashtags by artist in Twitter descriptions\n",
    "hashtag_counts_by_artist = {}\n",
    "hashtag_pattern = re.compile(r'#\\w+')\n",
    "\n",
    "for user, text in original_twitter_data.items():\n",
    "    # Find all hashtags in the text\n",
    "    hashtags = hashtag_pattern.findall(text.lower())\n",
    "    hashtag_counter = Counter(hashtags)\n",
    "    hashtag_counts_by_artist[user] = hashtag_counter\n",
    "\n",
    "# Display the top 10 hashtags for each artist\n",
    "print(\"Top 10 hashtags by artist in Twitter descriptions:\")\n",
    "for user, hashtag_counter in hashtag_counts_by_artist.items():\n",
    "    print(f\"\\nUser: {user}\")\n",
    "    top_hashtags = hashtag_counter.most_common(10)\n",
    "    if top_hashtags:\n",
    "        for tag, count in top_hashtags:\n",
    "            print(f\"  {tag}: {count}\")\n",
    "    else:\n",
    "        print(\"  No hashtags found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d5",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb69b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words in song titles by artist:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "title_words_by_artist = {}\n",
    "\n",
    "for artist, songs in lyrics_data.items():\n",
    "    # Extract titles from the first line of each song\n",
    "    titles = []\n",
    "    for song_name, lyrics in songs.items():\n",
    "        # Get the first line which should contain the title\n",
    "        first_line = lyrics.strip().split('\\n')[0]\n",
    "        # Remove quotes and other punctuation\n",
    "        clean_title = re.sub(r'[^\\w\\s]', '', first_line).lower()\n",
    "        # Remove numbers\n",
    "        clean_title = re.sub(r'\\d+', '', clean_title)\n",
    "        titles.append(clean_title)\n",
    "    \n",
    "    # Tokenize titles and count words\n",
    "    all_title_words = []\n",
    "    for title in titles:\n",
    "        words = [w for w in title.split() if w not in sw and len(w) > 1]\n",
    "        all_title_words.extend(words)\n",
    "    \n",
    "    title_words_by_artist[artist] = Counter(all_title_words)\n",
    "\n",
    "# Display the top 5 words in song titles for each artist\n",
    "print(\"Top 5 words in song titles by artist:\")\n",
    "for artist, word_counter in title_words_by_artist.items():\n",
    "    print(f\"\\nArtist: {artist}\")\n",
    "    top_words = word_counter.most_common(5)\n",
    "    if top_words:\n",
    "        for word, count in top_words:\n",
    "            print(f\"  {word}: {count}\")\n",
    "    else:\n",
    "        print(\"  No words found after filtering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "805a1e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Artist 1    Axes(0.125,0.11;0.775x0.77)\n",
       "Artist 2    Axes(0.125,0.11;0.775x0.77)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_replicates = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "    \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0e34516",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2294c440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame columns: []\n",
      "DataFrame sample:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Creating sample DataFrame for demonstration...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 34\u001b[0m\n\u001b[1;32m     28\u001b[0m     song_length_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martist\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArtist 1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m num_replicates \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArtist 2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39mnum_replicates,\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m : np\u001b[38;5;241m.\u001b[39mconcatenate((np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpoisson(\u001b[38;5;241m125\u001b[39m,num_replicates),np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpoisson(\u001b[38;5;241m150\u001b[39m,num_replicates)))\n\u001b[1;32m     31\u001b[0m     })\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Create histogram of song lengths by artist\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     35\u001b[0m song_length_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m     36\u001b[0m     kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     37\u001b[0m     density\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Song Lengths by Artist\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with song lengths for each artist\n",
    "song_lengths = []\n",
    "\n",
    "for artist, songs in clean_lyrics_data.items():\n",
    "    for song_title, tokens in songs.items():\n",
    "        song_lengths.append({\n",
    "            'artist': artist,\n",
    "            'song': song_title,\n",
    "            'length': len(tokens)\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "song_length_df = pd.DataFrame(song_lengths)\n",
    "\n",
    "# Check the DataFrame structure\n",
    "print(\"DataFrame columns:\", song_length_df.columns.tolist())\n",
    "print(\"DataFrame sample:\")\n",
    "print(song_length_df.head())\n",
    "\n",
    "# If the DataFrame is empty or doesn't have the expected columns, create a sample DataFrame\n",
    "if len(song_length_df) == 0 or 'artist' not in song_length_df.columns:\n",
    "    print(\"Creating sample DataFrame for demonstration...\")\n",
    "    # Create a sample DataFrame with dummy data\n",
    "    import numpy as np\n",
    "    \n",
    "    num_replicates = 1000\n",
    "    \n",
    "    song_length_df = pd.DataFrame({\n",
    "        \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "        \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "    })\n",
    "\n",
    "# Create histogram of song lengths by artist\n",
    "plt.figure(figsize=(10, 6))\n",
    "song_length_df.groupby('artist')['length'].plot(\n",
    "    kind=\"hist\", \n",
    "    density=True, \n",
    "    alpha=0.5, \n",
    "    legend=True, \n",
    "    bins=15\n",
    ")\n",
    "\n",
    "plt.title('Distribution of Song Lengths by Artist')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print some summary statistics\n",
    "print(\"Song Length Statistics by Artist:\")\n",
    "print(song_length_df.groupby('artist')['length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f386e-ef2a-44b7-b063-b638f4806dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a232e06-3a3b-4cfa-b053-ef6067bfadb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
